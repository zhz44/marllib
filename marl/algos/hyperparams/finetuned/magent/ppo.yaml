# PPO parameters

algo_args:
  batch_episode:  10
  batch_mode: "complete_episodes"
  lr: 0.0005
  iteration: 4
  entropy_coeff: 0.01
  clip_param: 0.2
  vf_clip_param: 20.0
